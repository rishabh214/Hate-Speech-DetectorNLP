{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92b885dd147dac19bd0a33db3cd0da100bd5bc23"
   },
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70282bce8b42a51e4d44f2c7d85c4ca9567b0fd4"
   },
   "outputs": [],
   "source": [
    "!pip install gensim --upgrade\n",
    "!pip install keras --upgrade\n",
    "!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "303e72966af732ddef0bd8108a321095314e44af"
   },
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "35e1a89dead5fd160e4c9a024a21d2e569fc89ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rishabh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8b01a07df001e4abcc745900336c4db06e455f3"
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "180f0dd2a95419e4602b5c0229822b0111c826f6"
   },
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# TEXT CLENAING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC \n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 8\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "# EXPORT\n",
    "KERAS_MODEL = \"model.h5\"\n",
    "WORD2VEC_MODEL = \"model.w2v\"\n",
    "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"encoder.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c3beecc618be68480b3d4f0de08d9d863da1dc1"
   },
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "bba8f91cd70de4f5ea0fb0870ae2029b6e3dcc24"
   },
   "outputs": [],
   "source": [
    "dataset_path = '/home/rishabh/NLP/hate speech/data.csv'\n",
    "df = pd.read_csv(dataset_path, encoding =DATASET_ENCODING , names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "936d499c00c4f1648bc16ca9d283c3b39be7fb10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1600000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7486ed895b813c5246f97b31b6162b0f65ff763b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "14074b59106cb9550440839e48b832223fc9502f"
   },
   "outputs": [],
   "source": [
    "decode_map = {0: \"HATE\", 4:\"NON HATE\"}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "4449d473187f647a195a6ac6986b009da32a7f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 556 ms, sys: 6.57 ms, total: 563 ms\n",
      "Wall time: 555 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.target = df.target.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4329b1573518b03e497213efa7676220734ebb4b"
   },
   "source": [
    "### Pre-Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "8aeee8b7b9ea11b749c7f91cd4787a7b50ed1a91"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "649ebcb97969b9ac4301138783704bb3d7846a49"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "f7f3e77ab9291d14687c49e71ba9b2b1e3323432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53 s, sys: 112 ms, total: 53.1 s\n",
      "Wall time: 53.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5f9714a8507409bbe780eebf2855a33e8e6ba37"
   },
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "d2b1179c968e3f3910c790ecf0c5b2cbb34b0e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 1280000\n",
      "TEST size: 320000\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=42)\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f08a28aab2c3d16d8b9681a7d5d07587153a1cd6"
   },
   "source": [
    "### Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "2461bf564de1b4414841933d0c1d1bee5f5cc5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.24 s, sys: 200 ms, total: 2.44 s\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in df_train.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "8e19b9f25801ba86420decc266d2b3e6fb44f1ea"
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "58d655af07653c594bec6bebcfb302a973b0ad9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-04 21:05:46,658 : INFO : collecting all words and their counts\n",
      "2020-12-04 21:05:46,661 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-12-04 21:05:46,695 : INFO : PROGRESS: at sentence #10000, processed 72565 words, keeping 14005 word types\n",
      "2020-12-04 21:05:46,722 : INFO : PROGRESS: at sentence #20000, processed 144393 words, keeping 21587 word types\n",
      "2020-12-04 21:05:46,765 : INFO : PROGRESS: at sentence #30000, processed 215826 words, keeping 27541 word types\n",
      "2020-12-04 21:05:46,794 : INFO : PROGRESS: at sentence #40000, processed 288271 words, keeping 32764 word types\n",
      "2020-12-04 21:05:46,823 : INFO : PROGRESS: at sentence #50000, processed 359772 words, keeping 37587 word types\n",
      "2020-12-04 21:05:46,852 : INFO : PROGRESS: at sentence #60000, processed 431431 words, keeping 42198 word types\n",
      "2020-12-04 21:05:46,880 : INFO : PROGRESS: at sentence #70000, processed 503103 words, keeping 46458 word types\n",
      "2020-12-04 21:05:46,909 : INFO : PROGRESS: at sentence #80000, processed 575709 words, keeping 50476 word types\n",
      "2020-12-04 21:05:46,937 : INFO : PROGRESS: at sentence #90000, processed 647100 words, keeping 54140 word types\n",
      "2020-12-04 21:05:46,967 : INFO : PROGRESS: at sentence #100000, processed 718681 words, keeping 57777 word types\n",
      "2020-12-04 21:05:46,992 : INFO : PROGRESS: at sentence #110000, processed 790696 words, keeping 61207 word types\n",
      "2020-12-04 21:05:47,022 : INFO : PROGRESS: at sentence #120000, processed 863134 words, keeping 64583 word types\n",
      "2020-12-04 21:05:47,044 : INFO : PROGRESS: at sentence #130000, processed 935111 words, keeping 67865 word types\n",
      "2020-12-04 21:05:47,071 : INFO : PROGRESS: at sentence #140000, processed 1006668 words, keeping 70966 word types\n",
      "2020-12-04 21:05:47,098 : INFO : PROGRESS: at sentence #150000, processed 1078512 words, keeping 74119 word types\n",
      "2020-12-04 21:05:47,131 : INFO : PROGRESS: at sentence #160000, processed 1149914 words, keeping 77187 word types\n",
      "2020-12-04 21:05:47,162 : INFO : PROGRESS: at sentence #170000, processed 1222145 words, keeping 80267 word types\n",
      "2020-12-04 21:05:47,191 : INFO : PROGRESS: at sentence #180000, processed 1294708 words, keeping 83393 word types\n",
      "2020-12-04 21:05:47,224 : INFO : PROGRESS: at sentence #190000, processed 1367608 words, keeping 86329 word types\n",
      "2020-12-04 21:05:47,254 : INFO : PROGRESS: at sentence #200000, processed 1439469 words, keeping 89103 word types\n",
      "2020-12-04 21:05:47,283 : INFO : PROGRESS: at sentence #210000, processed 1512099 words, keeping 91840 word types\n",
      "2020-12-04 21:05:47,305 : INFO : PROGRESS: at sentence #220000, processed 1584149 words, keeping 94636 word types\n",
      "2020-12-04 21:05:47,336 : INFO : PROGRESS: at sentence #230000, processed 1656354 words, keeping 97353 word types\n",
      "2020-12-04 21:05:47,360 : INFO : PROGRESS: at sentence #240000, processed 1728573 words, keeping 99975 word types\n",
      "2020-12-04 21:05:47,388 : INFO : PROGRESS: at sentence #250000, processed 1801102 words, keeping 102594 word types\n",
      "2020-12-04 21:05:47,417 : INFO : PROGRESS: at sentence #260000, processed 1873103 words, keeping 105162 word types\n",
      "2020-12-04 21:05:47,441 : INFO : PROGRESS: at sentence #270000, processed 1945245 words, keeping 107626 word types\n",
      "2020-12-04 21:05:47,470 : INFO : PROGRESS: at sentence #280000, processed 2017163 words, keeping 110141 word types\n",
      "2020-12-04 21:05:47,497 : INFO : PROGRESS: at sentence #290000, processed 2089574 words, keeping 112539 word types\n",
      "2020-12-04 21:05:47,527 : INFO : PROGRESS: at sentence #300000, processed 2160996 words, keeping 114893 word types\n",
      "2020-12-04 21:05:47,553 : INFO : PROGRESS: at sentence #310000, processed 2232913 words, keeping 117298 word types\n",
      "2020-12-04 21:05:47,579 : INFO : PROGRESS: at sentence #320000, processed 2305039 words, keeping 119693 word types\n",
      "2020-12-04 21:05:47,607 : INFO : PROGRESS: at sentence #330000, processed 2377119 words, keeping 122131 word types\n",
      "2020-12-04 21:05:47,635 : INFO : PROGRESS: at sentence #340000, processed 2449370 words, keeping 124416 word types\n",
      "2020-12-04 21:05:47,658 : INFO : PROGRESS: at sentence #350000, processed 2521564 words, keeping 126669 word types\n",
      "2020-12-04 21:05:47,693 : INFO : PROGRESS: at sentence #360000, processed 2593681 words, keeping 128912 word types\n",
      "2020-12-04 21:05:47,738 : INFO : PROGRESS: at sentence #370000, processed 2665692 words, keeping 131135 word types\n",
      "2020-12-04 21:05:47,779 : INFO : PROGRESS: at sentence #380000, processed 2737859 words, keeping 133403 word types\n",
      "2020-12-04 21:05:47,813 : INFO : PROGRESS: at sentence #390000, processed 2809848 words, keeping 135551 word types\n",
      "2020-12-04 21:05:47,850 : INFO : PROGRESS: at sentence #400000, processed 2882438 words, keeping 137742 word types\n",
      "2020-12-04 21:05:47,877 : INFO : PROGRESS: at sentence #410000, processed 2954075 words, keeping 139909 word types\n",
      "2020-12-04 21:05:47,904 : INFO : PROGRESS: at sentence #420000, processed 3026247 words, keeping 142144 word types\n",
      "2020-12-04 21:05:47,944 : INFO : PROGRESS: at sentence #430000, processed 3098659 words, keeping 144364 word types\n",
      "2020-12-04 21:05:47,972 : INFO : PROGRESS: at sentence #440000, processed 3170663 words, keeping 146439 word types\n",
      "2020-12-04 21:05:48,001 : INFO : PROGRESS: at sentence #450000, processed 3243344 words, keeping 148526 word types\n",
      "2020-12-04 21:05:48,032 : INFO : PROGRESS: at sentence #460000, processed 3315466 words, keeping 150610 word types\n",
      "2020-12-04 21:05:48,058 : INFO : PROGRESS: at sentence #470000, processed 3388295 words, keeping 152737 word types\n",
      "2020-12-04 21:05:48,099 : INFO : PROGRESS: at sentence #480000, processed 3460120 words, keeping 154757 word types\n",
      "2020-12-04 21:05:48,129 : INFO : PROGRESS: at sentence #490000, processed 3531883 words, keeping 156825 word types\n",
      "2020-12-04 21:05:48,153 : INFO : PROGRESS: at sentence #500000, processed 3604217 words, keeping 158859 word types\n",
      "2020-12-04 21:05:48,189 : INFO : PROGRESS: at sentence #510000, processed 3676427 words, keeping 160852 word types\n",
      "2020-12-04 21:05:48,220 : INFO : PROGRESS: at sentence #520000, processed 3749045 words, keeping 162863 word types\n",
      "2020-12-04 21:05:48,247 : INFO : PROGRESS: at sentence #530000, processed 3821622 words, keeping 164929 word types\n",
      "2020-12-04 21:05:48,280 : INFO : PROGRESS: at sentence #540000, processed 3893627 words, keeping 166840 word types\n",
      "2020-12-04 21:05:48,313 : INFO : PROGRESS: at sentence #550000, processed 3965477 words, keeping 168799 word types\n",
      "2020-12-04 21:05:48,339 : INFO : PROGRESS: at sentence #560000, processed 4038050 words, keeping 170802 word types\n",
      "2020-12-04 21:05:48,368 : INFO : PROGRESS: at sentence #570000, processed 4110296 words, keeping 172760 word types\n",
      "2020-12-04 21:05:48,394 : INFO : PROGRESS: at sentence #580000, processed 4182385 words, keeping 174635 word types\n",
      "2020-12-04 21:05:48,426 : INFO : PROGRESS: at sentence #590000, processed 4254632 words, keeping 176470 word types\n",
      "2020-12-04 21:05:48,465 : INFO : PROGRESS: at sentence #600000, processed 4326859 words, keeping 178350 word types\n",
      "2020-12-04 21:05:48,498 : INFO : PROGRESS: at sentence #610000, processed 4399183 words, keeping 180290 word types\n",
      "2020-12-04 21:05:48,524 : INFO : PROGRESS: at sentence #620000, processed 4471343 words, keeping 182129 word types\n",
      "2020-12-04 21:05:48,548 : INFO : PROGRESS: at sentence #630000, processed 4543286 words, keeping 184005 word types\n",
      "2020-12-04 21:05:48,586 : INFO : PROGRESS: at sentence #640000, processed 4615780 words, keeping 185835 word types\n",
      "2020-12-04 21:05:48,610 : INFO : PROGRESS: at sentence #650000, processed 4688481 words, keeping 187705 word types\n",
      "2020-12-04 21:05:48,641 : INFO : PROGRESS: at sentence #660000, processed 4760481 words, keeping 189439 word types\n",
      "2020-12-04 21:05:48,669 : INFO : PROGRESS: at sentence #670000, processed 4833024 words, keeping 191232 word types\n",
      "2020-12-04 21:05:48,696 : INFO : PROGRESS: at sentence #680000, processed 4904516 words, keeping 193177 word types\n",
      "2020-12-04 21:05:48,729 : INFO : PROGRESS: at sentence #690000, processed 4976968 words, keeping 194960 word types\n",
      "2020-12-04 21:05:48,760 : INFO : PROGRESS: at sentence #700000, processed 5049412 words, keeping 196725 word types\n",
      "2020-12-04 21:05:48,795 : INFO : PROGRESS: at sentence #710000, processed 5121976 words, keeping 198516 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-04 21:05:48,824 : INFO : PROGRESS: at sentence #720000, processed 5193881 words, keeping 200325 word types\n",
      "2020-12-04 21:05:48,865 : INFO : PROGRESS: at sentence #730000, processed 5265467 words, keeping 202133 word types\n",
      "2020-12-04 21:05:48,901 : INFO : PROGRESS: at sentence #740000, processed 5337518 words, keeping 203818 word types\n",
      "2020-12-04 21:05:48,929 : INFO : PROGRESS: at sentence #750000, processed 5409321 words, keeping 205535 word types\n",
      "2020-12-04 21:05:48,961 : INFO : PROGRESS: at sentence #760000, processed 5481512 words, keeping 207282 word types\n",
      "2020-12-04 21:05:48,990 : INFO : PROGRESS: at sentence #770000, processed 5554093 words, keeping 209076 word types\n",
      "2020-12-04 21:05:49,015 : INFO : PROGRESS: at sentence #780000, processed 5625382 words, keeping 210805 word types\n",
      "2020-12-04 21:05:49,045 : INFO : PROGRESS: at sentence #790000, processed 5698066 words, keeping 212618 word types\n",
      "2020-12-04 21:05:49,073 : INFO : PROGRESS: at sentence #800000, processed 5770880 words, keeping 214374 word types\n",
      "2020-12-04 21:05:49,107 : INFO : PROGRESS: at sentence #810000, processed 5843418 words, keeping 216009 word types\n",
      "2020-12-04 21:05:49,133 : INFO : PROGRESS: at sentence #820000, processed 5915628 words, keeping 217804 word types\n",
      "2020-12-04 21:05:49,158 : INFO : PROGRESS: at sentence #830000, processed 5987499 words, keeping 219585 word types\n",
      "2020-12-04 21:05:49,180 : INFO : PROGRESS: at sentence #840000, processed 6058973 words, keeping 221344 word types\n",
      "2020-12-04 21:05:49,207 : INFO : PROGRESS: at sentence #850000, processed 6131125 words, keeping 223002 word types\n",
      "2020-12-04 21:05:49,237 : INFO : PROGRESS: at sentence #860000, processed 6202951 words, keeping 224643 word types\n",
      "2020-12-04 21:05:49,271 : INFO : PROGRESS: at sentence #870000, processed 6275461 words, keeping 226362 word types\n",
      "2020-12-04 21:05:49,310 : INFO : PROGRESS: at sentence #880000, processed 6347661 words, keeping 227986 word types\n",
      "2020-12-04 21:05:49,337 : INFO : PROGRESS: at sentence #890000, processed 6419806 words, keeping 229634 word types\n",
      "2020-12-04 21:05:49,367 : INFO : PROGRESS: at sentence #900000, processed 6491644 words, keeping 231389 word types\n",
      "2020-12-04 21:05:49,408 : INFO : PROGRESS: at sentence #910000, processed 6564022 words, keeping 233050 word types\n",
      "2020-12-04 21:05:49,436 : INFO : PROGRESS: at sentence #920000, processed 6636228 words, keeping 234686 word types\n",
      "2020-12-04 21:05:49,465 : INFO : PROGRESS: at sentence #930000, processed 6708573 words, keeping 236393 word types\n",
      "2020-12-04 21:05:49,488 : INFO : PROGRESS: at sentence #940000, processed 6779956 words, keeping 238052 word types\n",
      "2020-12-04 21:05:49,519 : INFO : PROGRESS: at sentence #950000, processed 6852599 words, keeping 239716 word types\n",
      "2020-12-04 21:05:49,549 : INFO : PROGRESS: at sentence #960000, processed 6924717 words, keeping 241354 word types\n",
      "2020-12-04 21:05:49,583 : INFO : PROGRESS: at sentence #970000, processed 6996992 words, keeping 242980 word types\n",
      "2020-12-04 21:05:49,613 : INFO : PROGRESS: at sentence #980000, processed 7068402 words, keeping 244646 word types\n",
      "2020-12-04 21:05:49,643 : INFO : PROGRESS: at sentence #990000, processed 7140346 words, keeping 246186 word types\n",
      "2020-12-04 21:05:49,681 : INFO : PROGRESS: at sentence #1000000, processed 7211757 words, keeping 247726 word types\n",
      "2020-12-04 21:05:49,715 : INFO : PROGRESS: at sentence #1010000, processed 7283267 words, keeping 249288 word types\n",
      "2020-12-04 21:05:49,742 : INFO : PROGRESS: at sentence #1020000, processed 7355299 words, keeping 250860 word types\n",
      "2020-12-04 21:05:49,778 : INFO : PROGRESS: at sentence #1030000, processed 7426918 words, keeping 252366 word types\n",
      "2020-12-04 21:05:49,807 : INFO : PROGRESS: at sentence #1040000, processed 7498815 words, keeping 253930 word types\n",
      "2020-12-04 21:05:49,848 : INFO : PROGRESS: at sentence #1050000, processed 7570499 words, keeping 255471 word types\n",
      "2020-12-04 21:05:49,878 : INFO : PROGRESS: at sentence #1060000, processed 7643251 words, keeping 257035 word types\n",
      "2020-12-04 21:05:49,905 : INFO : PROGRESS: at sentence #1070000, processed 7714721 words, keeping 258509 word types\n",
      "2020-12-04 21:05:49,933 : INFO : PROGRESS: at sentence #1080000, processed 7787371 words, keeping 260071 word types\n",
      "2020-12-04 21:05:49,955 : INFO : PROGRESS: at sentence #1090000, processed 7859336 words, keeping 261683 word types\n",
      "2020-12-04 21:05:49,985 : INFO : PROGRESS: at sentence #1100000, processed 7932029 words, keeping 263278 word types\n",
      "2020-12-04 21:05:50,017 : INFO : PROGRESS: at sentence #1110000, processed 8004146 words, keeping 264800 word types\n",
      "2020-12-04 21:05:50,041 : INFO : PROGRESS: at sentence #1120000, processed 8075880 words, keeping 266309 word types\n",
      "2020-12-04 21:05:50,080 : INFO : PROGRESS: at sentence #1130000, processed 8148163 words, keeping 267826 word types\n",
      "2020-12-04 21:05:50,103 : INFO : PROGRESS: at sentence #1140000, processed 8220487 words, keeping 269391 word types\n",
      "2020-12-04 21:05:50,128 : INFO : PROGRESS: at sentence #1150000, processed 8292498 words, keeping 270894 word types\n",
      "2020-12-04 21:05:50,151 : INFO : PROGRESS: at sentence #1160000, processed 8363838 words, keeping 272400 word types\n",
      "2020-12-04 21:05:50,179 : INFO : PROGRESS: at sentence #1170000, processed 8435510 words, keeping 273970 word types\n",
      "2020-12-04 21:05:50,203 : INFO : PROGRESS: at sentence #1180000, processed 8507795 words, keeping 275521 word types\n",
      "2020-12-04 21:05:50,227 : INFO : PROGRESS: at sentence #1190000, processed 8579080 words, keeping 277007 word types\n",
      "2020-12-04 21:05:50,256 : INFO : PROGRESS: at sentence #1200000, processed 8650606 words, keeping 278457 word types\n",
      "2020-12-04 21:05:50,281 : INFO : PROGRESS: at sentence #1210000, processed 8721893 words, keeping 279959 word types\n",
      "2020-12-04 21:05:50,310 : INFO : PROGRESS: at sentence #1220000, processed 8793795 words, keeping 281427 word types\n",
      "2020-12-04 21:05:50,346 : INFO : PROGRESS: at sentence #1230000, processed 8865726 words, keeping 282981 word types\n",
      "2020-12-04 21:05:50,374 : INFO : PROGRESS: at sentence #1240000, processed 8938173 words, keeping 284542 word types\n",
      "2020-12-04 21:05:50,402 : INFO : PROGRESS: at sentence #1250000, processed 9010842 words, keeping 286064 word types\n",
      "2020-12-04 21:05:50,425 : INFO : PROGRESS: at sentence #1260000, processed 9083261 words, keeping 287521 word types\n",
      "2020-12-04 21:05:50,453 : INFO : PROGRESS: at sentence #1270000, processed 9155616 words, keeping 288987 word types\n",
      "2020-12-04 21:05:50,485 : INFO : collected 290418 word types from a corpus of 9227204 raw words and 1280000 sentences\n",
      "2020-12-04 21:05:50,486 : INFO : Loading a fresh vocabulary\n",
      "2020-12-04 21:05:50,958 : INFO : effective_min_count=10 retains 30369 unique words (10% of original 290418, drops 260049)\n",
      "2020-12-04 21:05:50,958 : INFO : effective_min_count=10 leaves 8780739 word corpus (95% of original 9227204, drops 446465)\n",
      "2020-12-04 21:05:51,108 : INFO : deleting the raw counts dictionary of 290418 items\n",
      "2020-12-04 21:05:51,115 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-12-04 21:05:51,117 : INFO : downsampling leaves estimated 8222658 word corpus (93.6% of prior 8780739)\n",
      "2020-12-04 21:05:51,224 : INFO : estimated required memory for 30369 words and 300 dimensions: 88070100 bytes\n",
      "2020-12-04 21:05:51,225 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "72a5628ca81fd4b8983c12d93ae0bf950b86b6ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 30369\n"
     ]
    }
   ],
   "source": [
    "words = w2v_model.wv.vocab.keys()\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "68c3e4a5ba07cac3dee67f78ecdd1404c7f83f14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-04 21:05:58,030 : INFO : training model with 8 workers on 30369 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=7\n",
      "2020-12-04 21:05:59,081 : INFO : EPOCH 1 - PROGRESS: at 6.08% examples, 480436 words/s, in_qsize 16, out_qsize 1\n",
      "2020-12-04 21:06:00,087 : INFO : EPOCH 1 - PROGRESS: at 12.93% examples, 518903 words/s, in_qsize 13, out_qsize 2\n",
      "2020-12-04 21:06:01,090 : INFO : EPOCH 1 - PROGRESS: at 19.73% examples, 532018 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:02,094 : INFO : EPOCH 1 - PROGRESS: at 25.91% examples, 525606 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:03,137 : INFO : EPOCH 1 - PROGRESS: at 32.19% examples, 519402 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:04,172 : INFO : EPOCH 1 - PROGRESS: at 39.00% examples, 523260 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:05,190 : INFO : EPOCH 1 - PROGRESS: at 45.92% examples, 528444 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:06,214 : INFO : EPOCH 1 - PROGRESS: at 51.96% examples, 523328 words/s, in_qsize 15, out_qsize 7\n",
      "2020-12-04 21:06:07,222 : INFO : EPOCH 1 - PROGRESS: at 59.12% examples, 529909 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:06:08,224 : INFO : EPOCH 1 - PROGRESS: at 65.82% examples, 531967 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:09,227 : INFO : EPOCH 1 - PROGRESS: at 72.32% examples, 532050 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:06:10,258 : INFO : EPOCH 1 - PROGRESS: at 79.05% examples, 532327 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:11,262 : INFO : EPOCH 1 - PROGRESS: at 85.77% examples, 533656 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:12,263 : INFO : EPOCH 1 - PROGRESS: at 92.17% examples, 533044 words/s, in_qsize 15, out_qsize 2\n",
      "2020-12-04 21:06:13,286 : INFO : EPOCH 1 - PROGRESS: at 99.12% examples, 534687 words/s, in_qsize 9, out_qsize 0\n",
      "2020-12-04 21:06:13,302 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-12-04 21:06:13,327 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-12-04 21:06:13,337 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-12-04 21:06:13,386 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-04 21:06:13,391 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-04 21:06:13,396 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-04 21:06:13,402 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-04 21:06:13,418 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-04 21:06:13,419 : INFO : EPOCH - 1 : training on 9227204 raw words (8222377 effective words) took 15.4s, 534766 effective words/s\n",
      "2020-12-04 21:06:14,446 : INFO : EPOCH 2 - PROGRESS: at 5.75% examples, 467451 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:06:15,454 : INFO : EPOCH 2 - PROGRESS: at 12.71% examples, 516790 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:16,469 : INFO : EPOCH 2 - PROGRESS: at 19.40% examples, 525694 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:17,480 : INFO : EPOCH 2 - PROGRESS: at 25.70% examples, 522100 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:06:18,496 : INFO : EPOCH 2 - PROGRESS: at 32.41% examples, 526414 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:19,510 : INFO : EPOCH 2 - PROGRESS: at 39.11% examples, 529492 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:20,517 : INFO : EPOCH 2 - PROGRESS: at 45.81% examples, 532159 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:21,560 : INFO : EPOCH 2 - PROGRESS: at 52.62% examples, 533016 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:22,589 : INFO : EPOCH 2 - PROGRESS: at 59.12% examples, 531510 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:23,622 : INFO : EPOCH 2 - PROGRESS: at 65.60% examples, 530051 words/s, in_qsize 13, out_qsize 2\n",
      "2020-12-04 21:06:24,656 : INFO : EPOCH 2 - PROGRESS: at 72.64% examples, 532867 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:06:25,691 : INFO : EPOCH 2 - PROGRESS: at 79.49% examples, 533602 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:26,697 : INFO : EPOCH 2 - PROGRESS: at 85.88% examples, 532777 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:27,720 : INFO : EPOCH 2 - PROGRESS: at 92.83% examples, 534462 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:28,704 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-12-04 21:06:28,719 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-12-04 21:06:28,725 : INFO : EPOCH 2 - PROGRESS: at 99.45% examples, 534955 words/s, in_qsize 5, out_qsize 1\n",
      "2020-12-04 21:06:28,729 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-12-04 21:06:28,749 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-04 21:06:28,783 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-04 21:06:28,785 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-04 21:06:28,790 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-04 21:06:28,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-04 21:06:28,804 : INFO : EPOCH - 2 : training on 9227204 raw words (8222874 effective words) took 15.4s, 535083 effective words/s\n",
      "2020-12-04 21:06:29,841 : INFO : EPOCH 3 - PROGRESS: at 5.97% examples, 478023 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:30,858 : INFO : EPOCH 3 - PROGRESS: at 12.82% examples, 515218 words/s, in_qsize 15, out_qsize 1\n",
      "2020-12-04 21:06:31,874 : INFO : EPOCH 3 - PROGRESS: at 19.51% examples, 524409 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:32,906 : INFO : EPOCH 3 - PROGRESS: at 26.23% examples, 527148 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:06:33,917 : INFO : EPOCH 3 - PROGRESS: at 32.73% examples, 527466 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:34,924 : INFO : EPOCH 3 - PROGRESS: at 39.32% examples, 529494 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:35,928 : INFO : EPOCH 3 - PROGRESS: at 45.81% examples, 529850 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:06:36,972 : INFO : EPOCH 3 - PROGRESS: at 52.40% examples, 528690 words/s, in_qsize 12, out_qsize 3\n",
      "2020-12-04 21:06:38,004 : INFO : EPOCH 3 - PROGRESS: at 59.44% examples, 532366 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:06:39,012 : INFO : EPOCH 3 - PROGRESS: at 65.83% examples, 531221 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:06:40,026 : INFO : EPOCH 3 - PROGRESS: at 72.43% examples, 531668 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:41,048 : INFO : EPOCH 3 - PROGRESS: at 79.38% examples, 533808 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:06:42,068 : INFO : EPOCH 3 - PROGRESS: at 85.98% examples, 533698 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:43,085 : INFO : EPOCH 3 - PROGRESS: at 92.50% examples, 533110 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:06:44,053 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-12-04 21:06:44,070 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-12-04 21:06:44,108 : INFO : EPOCH 3 - PROGRESS: at 99.45% examples, 534778 words/s, in_qsize 5, out_qsize 1\n",
      "2020-12-04 21:06:44,124 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-12-04 21:06:44,128 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-04 21:06:44,133 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-04 21:06:44,152 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-04 21:06:44,152 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-04 21:06:44,166 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-04 21:06:44,167 : INFO : EPOCH - 3 : training on 9227204 raw words (8221671 effective words) took 15.4s, 535598 effective words/s\n",
      "2020-12-04 21:06:45,196 : INFO : EPOCH 4 - PROGRESS: at 6.29% examples, 508701 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:46,200 : INFO : EPOCH 4 - PROGRESS: at 12.60% examples, 511662 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:47,237 : INFO : EPOCH 4 - PROGRESS: at 19.30% examples, 518525 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-04 21:06:48,280 : INFO : EPOCH 4 - PROGRESS: at 26.23% examples, 525824 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:49,290 : INFO : EPOCH 4 - PROGRESS: at 32.41% examples, 521272 words/s, in_qsize 15, out_qsize 2\n",
      "2020-12-04 21:06:50,301 : INFO : EPOCH 4 - PROGRESS: at 39.00% examples, 523867 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:06:51,309 : INFO : EPOCH 4 - PROGRESS: at 45.16% examples, 520995 words/s, in_qsize 15, out_qsize 2\n",
      "2020-12-04 21:06:52,329 : INFO : EPOCH 4 - PROGRESS: at 51.64% examples, 521455 words/s, in_qsize 15, out_qsize 3\n",
      "2020-12-04 21:06:53,337 : INFO : EPOCH 4 - PROGRESS: at 58.47% examples, 525365 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:54,343 : INFO : EPOCH 4 - PROGRESS: at 65.17% examples, 527675 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:06:55,350 : INFO : EPOCH 4 - PROGRESS: at 71.67% examples, 527967 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:06:56,396 : INFO : EPOCH 4 - PROGRESS: at 78.29% examples, 527906 words/s, in_qsize 15, out_qsize 1\n",
      "2020-12-04 21:06:57,396 : INFO : EPOCH 4 - PROGRESS: at 85.13% examples, 529780 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:06:58,426 : INFO : EPOCH 4 - PROGRESS: at 91.74% examples, 529581 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:06:59,427 : INFO : EPOCH 4 - PROGRESS: at 98.79% examples, 532788 words/s, in_qsize 12, out_qsize 0\n",
      "2020-12-04 21:06:59,527 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-12-04 21:06:59,533 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-12-04 21:06:59,539 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-12-04 21:06:59,549 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-04 21:06:59,577 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-04 21:06:59,607 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-04 21:06:59,613 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-04 21:06:59,621 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-04 21:06:59,623 : INFO : EPOCH - 4 : training on 9227204 raw words (8222391 effective words) took 15.4s, 532460 effective words/s\n",
      "2020-12-04 21:07:00,644 : INFO : EPOCH 5 - PROGRESS: at 5.97% examples, 487754 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:01,650 : INFO : EPOCH 5 - PROGRESS: at 12.60% examples, 514130 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:07:02,689 : INFO : EPOCH 5 - PROGRESS: at 19.08% examples, 514157 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:03,696 : INFO : EPOCH 5 - PROGRESS: at 26.02% examples, 527124 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:07:04,709 : INFO : EPOCH 5 - PROGRESS: at 32.41% examples, 525485 words/s, in_qsize 13, out_qsize 1\n",
      "2020-12-04 21:07:05,718 : INFO : EPOCH 5 - PROGRESS: at 38.79% examples, 524663 words/s, in_qsize 15, out_qsize 1\n",
      "2020-12-04 21:07:06,759 : INFO : EPOCH 5 - PROGRESS: at 45.59% examples, 526785 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:07:07,773 : INFO : EPOCH 5 - PROGRESS: at 52.07% examples, 526846 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:08,786 : INFO : EPOCH 5 - PROGRESS: at 58.69% examples, 527996 words/s, in_qsize 16, out_qsize 1\n",
      "2020-12-04 21:07:09,803 : INFO : EPOCH 5 - PROGRESS: at 65.61% examples, 531216 words/s, in_qsize 14, out_qsize 2\n",
      "2020-12-04 21:07:10,816 : INFO : EPOCH 5 - PROGRESS: at 71.99% examples, 530109 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:11,834 : INFO : EPOCH 5 - PROGRESS: at 78.95% examples, 532593 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:12,842 : INFO : EPOCH 5 - PROGRESS: at 85.66% examples, 533773 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:13,852 : INFO : EPOCH 5 - PROGRESS: at 92.28% examples, 534052 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:14,881 : INFO : EPOCH 5 - PROGRESS: at 99.23% examples, 535383 words/s, in_qsize 7, out_qsize 2\n",
      "2020-12-04 21:07:14,883 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-12-04 21:07:14,892 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-12-04 21:07:14,894 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-12-04 21:07:14,929 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-04 21:07:14,935 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-04 21:07:14,936 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-04 21:07:14,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-04 21:07:14,955 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-04 21:07:14,956 : INFO : EPOCH - 5 : training on 9227204 raw words (8223312 effective words) took 15.3s, 536916 effective words/s\n",
      "2020-12-04 21:07:15,973 : INFO : EPOCH 6 - PROGRESS: at 6.08% examples, 496244 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:16,979 : INFO : EPOCH 6 - PROGRESS: at 12.93% examples, 527318 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:17,994 : INFO : EPOCH 6 - PROGRESS: at 19.30% examples, 524102 words/s, in_qsize 16, out_qsize 4\n",
      "2020-12-04 21:07:19,007 : INFO : EPOCH 6 - PROGRESS: at 26.34% examples, 536119 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:20,064 : INFO : EPOCH 6 - PROGRESS: at 33.17% examples, 534934 words/s, in_qsize 16, out_qsize 1\n",
      "2020-12-04 21:07:21,071 : INFO : EPOCH 6 - PROGRESS: at 40.19% examples, 541570 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:22,087 : INFO : EPOCH 6 - PROGRESS: at 46.46% examples, 536861 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:23,092 : INFO : EPOCH 6 - PROGRESS: at 53.05% examples, 537414 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:07:24,097 : INFO : EPOCH 6 - PROGRESS: at 59.77% examples, 538775 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:25,121 : INFO : EPOCH 6 - PROGRESS: at 66.58% examples, 539675 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:26,129 : INFO : EPOCH 6 - PROGRESS: at 73.30% examples, 540409 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:07:27,153 : INFO : EPOCH 6 - PROGRESS: at 79.92% examples, 539597 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:07:28,187 : INFO : EPOCH 6 - PROGRESS: at 87.18% examples, 542547 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:29,202 : INFO : EPOCH 6 - PROGRESS: at 93.92% examples, 542588 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:07:30,010 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-12-04 21:07:30,028 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-12-04 21:07:30,032 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-12-04 21:07:30,037 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-04 21:07:30,052 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-04 21:07:30,060 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-04 21:07:30,090 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-04 21:07:30,094 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-04 21:07:30,095 : INFO : EPOCH - 6 : training on 9227204 raw words (8223030 effective words) took 15.1s, 543605 effective words/s\n",
      "2020-12-04 21:07:31,109 : INFO : EPOCH 7 - PROGRESS: at 6.19% examples, 506157 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:32,115 : INFO : EPOCH 7 - PROGRESS: at 12.82% examples, 523093 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:07:33,140 : INFO : EPOCH 7 - PROGRESS: at 19.62% examples, 531277 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:34,150 : INFO : EPOCH 7 - PROGRESS: at 26.34% examples, 535219 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:35,153 : INFO : EPOCH 7 - PROGRESS: at 33.16% examples, 539966 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:36,200 : INFO : EPOCH 7 - PROGRESS: at 39.87% examples, 537855 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:07:37,239 : INFO : EPOCH 7 - PROGRESS: at 46.67% examples, 538111 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:38,274 : INFO : EPOCH 7 - PROGRESS: at 52.95% examples, 533211 words/s, in_qsize 15, out_qsize 4\n",
      "2020-12-04 21:07:39,276 : INFO : EPOCH 7 - PROGRESS: at 59.87% examples, 537135 words/s, in_qsize 16, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-04 21:07:40,300 : INFO : EPOCH 7 - PROGRESS: at 66.79% examples, 539102 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:41,305 : INFO : EPOCH 7 - PROGRESS: at 73.19% examples, 537618 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:42,307 : INFO : EPOCH 7 - PROGRESS: at 80.03% examples, 539425 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:43,324 : INFO : EPOCH 7 - PROGRESS: at 86.31% examples, 537015 words/s, in_qsize 11, out_qsize 4\n",
      "2020-12-04 21:07:44,349 : INFO : EPOCH 7 - PROGRESS: at 93.49% examples, 539627 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:45,222 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-12-04 21:07:45,236 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-12-04 21:07:45,249 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-12-04 21:07:45,269 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-04 21:07:45,286 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-04 21:07:45,293 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-04 21:07:45,295 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-04 21:07:45,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-04 21:07:45,324 : INFO : EPOCH - 7 : training on 9227204 raw words (8221462 effective words) took 15.2s, 540255 effective words/s\n",
      "2020-12-04 21:07:46,362 : INFO : EPOCH 8 - PROGRESS: at 6.18% examples, 493361 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:47,393 : INFO : EPOCH 8 - PROGRESS: at 12.93% examples, 514692 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:48,400 : INFO : EPOCH 8 - PROGRESS: at 19.73% examples, 528714 words/s, in_qsize 16, out_qsize 0\n",
      "2020-12-04 21:07:49,415 : INFO : EPOCH 8 - PROGRESS: at 26.23% examples, 528136 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:50,426 : INFO : EPOCH 8 - PROGRESS: at 33.05% examples, 533492 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:51,444 : INFO : EPOCH 8 - PROGRESS: at 39.44% examples, 530691 words/s, in_qsize 10, out_qsize 5\n",
      "2020-12-04 21:07:52,445 : INFO : EPOCH 8 - PROGRESS: at 46.35% examples, 536148 words/s, in_qsize 14, out_qsize 1\n",
      "2020-12-04 21:07:53,461 : INFO : EPOCH 8 - PROGRESS: at 52.95% examples, 536045 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:54,478 : INFO : EPOCH 8 - PROGRESS: at 59.55% examples, 535860 words/s, in_qsize 15, out_qsize 1\n",
      "2020-12-04 21:07:55,493 : INFO : EPOCH 8 - PROGRESS: at 66.58% examples, 539298 words/s, in_qsize 16, out_qsize 1\n",
      "2020-12-04 21:07:56,495 : INFO : EPOCH 8 - PROGRESS: at 73.08% examples, 538739 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:57,497 : INFO : EPOCH 8 - PROGRESS: at 79.49% examples, 537563 words/s, in_qsize 16, out_qsize 2\n",
      "2020-12-04 21:07:58,503 : INFO : EPOCH 8 - PROGRESS: at 86.53% examples, 540437 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:07:59,518 : INFO : EPOCH 8 - PROGRESS: at 93.16% examples, 540091 words/s, in_qsize 15, out_qsize 0\n",
      "2020-12-04 21:08:00,443 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-12-04 21:08:00,461 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-12-04 21:08:00,462 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-12-04 21:08:00,480 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-04 21:08:00,504 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-04 21:08:00,510 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-04 21:08:00,511 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-04 21:08:00,511 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-04 21:08:00,512 : INFO : EPOCH - 8 : training on 9227204 raw words (8222978 effective words) took 15.2s, 541743 effective words/s\n",
      "2020-12-04 21:08:00,513 : INFO : training on a 73817632 raw words (65780095 effective words) took 122.5s, 537062 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 36s, sys: 1.9 s, total: 7min 38s\n",
      "Wall time: 2min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(65780095, 73817632)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "27cc2651c74227115d8bfd8c40e5618048e05edd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2020-12-04 21:08:00,542 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('adore', 0.5728391408920288),\n",
       " ('luv', 0.5702308416366577),\n",
       " ('loved', 0.517593502998352),\n",
       " ('loves', 0.5084329843521118),\n",
       " ('loooove', 0.4869951605796814),\n",
       " ('looove', 0.4839927554130554),\n",
       " ('loove', 0.4672917127609253),\n",
       " ('loveee', 0.4425637722015381),\n",
       " ('lovee', 0.4396896958351135),\n",
       " ('sings', 0.4157412648200989)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e13563644468037258598637b49373ca96b9b879"
   },
   "source": [
    "### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "6852bc709a7cd20173cbeeb218505078f8f37c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 290419\n",
      "CPU times: user 21.1 s, sys: 59.9 ms, total: 21.2 s\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "45de439df3015030c71f84c2d170346936a1d68f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.2 s, sys: 493 ms, total: 34.7 s\n",
      "Wall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen=SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text), maxlen=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "03b35903fc6260e190d6928d240ef7432de117fc"
   },
   "source": [
    "### Label Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "33676e0efa39e97d89bd650b8b4eae933a22fbf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NON HATE', 'HATE']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_train.target.unique().tolist()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "04239a9bef76e7922fd86098a5601dfde8ee4665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (1280000, 1)\n",
      "y_test (320000, 1)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.target.tolist())\n",
    "\n",
    "y_train = encoder.transform(df_train.target.tolist())\n",
    "y_test = encoder.transform(df_test.target.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "04299c886911ca135583ab64878f213939a2990c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (1280000, 300)\n",
      "y_train (1280000, 1)\n",
      "\n",
      "x_test (320000, 300)\n",
      "y_test (320000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print()\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "232533fb27b7be99d9b8c2f8fb22c9c6bf121a6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "233c0ea94055a03e2e7df3e2a13d036ec963484f"
   },
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "9ab488374b59e3f30f8b1ea92767d853c4846bac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290419, 300)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "833279d91e4286065968237fb5f2a0c2dd4d246c"
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b299ef78f94c2085942c993a2d58753a7476305a"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "e775ef4f1b74e6412457181383c39f2df554ef3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 300)          87125700  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 87,286,201\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 87,125,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28d22eafd0c7d798dcf3d742bc92fb8577939e6c"
   },
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "1331e08d590bb2aa2033706c8faca217afc0f1c3"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7733127cb8b380e0c807268903bf4d03ef92542"
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "a688df590386f5748da6fe00b01904fe6c71619e"
   },
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmodel = keras.models.load_model('/home/rishabh/NLP/hate speech/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d0873633dd49179c8cae17377641b97d323ef3b"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "2b659d390c6577dc5cdb6b6297934279b4e801d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - ETA: 0s - loss: 0.4992 - accuracy: 0.7535WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-04 20:21:01,046 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 10744s 10s/step - loss: 0.4992 - accuracy: 0.7535 - val_loss: 0.4656 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "CPU times: user 11h 7min 37s, sys: 24min 43s, total: 11h 32min 20s\n",
      "Wall time: 2h 59min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=1,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "267258196d96796ac69a7b8c466314bcf5d6ee42"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "98ecd8f1b8b74594c3ea775dd68a094e92458022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 827s 3s/step - loss: 0.4646 - accuracy: 0.7781\n",
      "\n",
      "ACCURACY: 0.7781187295913696\n",
      "LOSS: 0.4646095633506775\n",
      "CPU times: user 49min 17s, sys: 2min 34s, total: 51min 52s\n",
      "Wall time: 13min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "print()\n",
    "print(\"ACCURACY:\",score[1])\n",
    "print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "cc363c54782894757f5ea8820c6a170f2e16ef93"
   },
   "outputs": [],
   "source": [
    "def decode_sentiment(score):\n",
    "    return 'HATE' if score < 0.5 else 'NON HATE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    start_at = time.time()\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    # Predict\n",
    "    score = lmodel.predict([x_test])[0]\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score)\n",
    "\n",
    "    return {\"label\": label, \"score\": float(score),\n",
    "       \"elapsed_time\": time.time()-start_at}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'NON HATE',\n",
       " 'score': 0.9656286239624023,\n",
       " 'elapsed_time': 1.1235954761505127}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I love the music\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'HATE',\n",
       " 'score': 0.010753682814538479,\n",
       " 'elapsed_time': 0.1017141342163086}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I hate the rain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'HATE',\n",
       " 'score': 0.2742375433444977,\n",
       " 'elapsed_time': 0.09618854522705078}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"i don't know what i'm doing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'HATE',\n",
       " 'score': 0.16064141690731049,\n",
       " 'elapsed_time': 0.07689070701599121}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"i will kill myself\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
